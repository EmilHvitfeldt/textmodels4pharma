<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Modeling</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emil Hvitfeldt" />
    <meta name="date" content="2020-10-09" />
    <script src="libs/header-attrs-2.4/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <link href="libs/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, title-slide

# Modeling
## R/Pharma 2020 Text modeling workshop
### Emil Hvitfeldt
### 2020-10-09

---









# Text as data

Let's take a look at the data again


```r
library(tidyverse)
library(animals)

glimpse(animals)
```

```
## Rows: 610
## Columns: 4
## $ text        &lt;chr&gt; "Aardvark Classification and Evolution\nAardvarks are smaâ€¦
## $ diet        &lt;chr&gt; "Omnivore", "Unknown", "Carnivore", "Unknown", "Unknown",â€¦
## $ lifestyle   &lt;chr&gt; "Nocturnal", NA, "Diurnal", NA, NA, "Diurnal", "Nocturnalâ€¦
## $ mean_weight &lt;dbl&gt; 70.0000, NA, 4.5000, NA, NA, 4500.0000, 2.9500, 0.1225, 1â€¦
```

---

# Text as data


```r
animals %&gt;%
  sample_n(1) %&gt;%
  pull(text)
```

```
## [1] "The guppy (also known as the millionfish) is a small colourful species of freshwater tropical fish that is found naturally in the rivers and lakes of South America. There are nearly 300 different types of guppy spread throughout Barbados, Brazil, Guyana, Netherlands Antilles, Trinidad and Tobago, and Venezuela.\nThe guppy is one of the most popular types of aquarium tropical fish in the world as they are small, colourful and easier to keep than many other species of fish. The guppy generally lives from 3 to 5 years old in captivity and slightly less in the wild.\nThe guppy has been introduced to most other countries mainly as a method of mosquito prevention as the guppy eats the mosquito larva before they are able to fly, therefore slowing down the spread of malaria.\nThe guppy is an extremely colourful fish and often displays elaborate patterns on its tail fin. The female guppy and the male guppy can be identified quite easily as the female guppy has a small, patterned tail where the tail of the male guppy is much longer and generally has fewer markings. The female guppy also tends to be larger in size than the male guppy.\nThe guppy gives birth to live young, meaning that the eggs are first incubated inside the female guppy and hatch there too. The incubation period of the guppy is about a month after which the female guppy can give birth to up to 100 baby guppies, which are called fry. As soon as they are born, the guppy fry are able to eat and swim around freely. The guppy fry are also able to sense and avoid danger which is important when around older guppies as they often eat the fry. The guppy fry have matured in adult guppies within a couple of months.\nAfter mating just once with a male guppy, the female guppy is able to give birth numerous times. The female guppy stores the sperm of the male guppy inside her and just hours after giving birth to her fry, the female guppy is ready to become pregnant again and will do so using the stored sperm (hence why the guppy is often called the millionfish).\nThe guppy is an omnivorous animal and eats a wide range of organic matter that is available in the water. The guppy mainly feeds on algae and brine shrimp, and often eat particles of food from the water that have been left by a larger fish.\nThe guppy has many natural predators in the wild (and in tanks) mainly due to their small size and their elaborate fins often attract unwanted attention. Birds such as kingfishers and larger fish are the primary predators of the guppy, so naturally, guppies that are kept in a tank should be kept with other very small fish to prevent them from being eaten."
```

---

# Text as data


--

- Text like this can be used for **supervised** or **predictive** modeling


--


- We can build both regression and classification models with text data


--


- We can use the ways language exhibits organization to create features for modeling


---

# Modeling Packages


```r
library(tidymodels)
library(textrecipes)
```

- [tidymodels](https://www.tidymodels.org/) is a collection of packages for modeling and machine learning using tidyverse principles
- [textrecipes](https://textrecipes.tidymodels.org/) extends the recipes package to handle text preprocessing

---

# Modeling workflow

![](images/tidymodels-textrecipes.png)

---

.pull-left[
# Modeling task

You are a new zoo keeper and your job is to figure out what to feed each animal based on a written description and some other metrics
]

--

.pull-right[
## Question

Is this a realistic problem to have?

Would it be a good use-case for Machine learning?

<div class="countdown" id="timer_5f7ff9d0" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

]

---

# Notes

- This could be better handled by an expert
- Disastrous results with misclassifications
- Overlap between classes
- Has an "unknown" field
- Uses both numeric/factor variables and text variables

---

# Class imbalance

&lt;img src="index_files/figure-html/unnamed-chunk-8-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

class: inverse, right, middle

# Let's approach this as a **multiclass classification task**

---

---

# Data splitting

The testing set is a precious resource which can be used only once

&lt;img src="index_files/figure-html/all-split-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

# Data splitting

## With {yardstick}


```r
set.seed(1234)
animals_split &lt;- initial_split(animals)

animals_training &lt;- training(animals_split)
animals_testing &lt;- testing(animals_split)
```

---

# Your turn #4

Specify stratification variable `diet` and extract the `testing()` and `training()` dataset


```r
set.seed(1234)
animals_split &lt;- initial_split(animals, strata = ___)

animals_split

animals_training &lt;- ___(animals_split)
animals_testing &lt;- ___(animals_split)
```

---

# Your turn #4 - results

Setting `strata = diet` makes sure that the proportions of diet is preserved in the split


```r
set.seed(1234)
animals_split &lt;- initial_split(animals, strata = diet)

animals_split
```

```
## &lt;Analysis/Assess/Total&gt;
## &lt;459/151/610&gt;
```

```r
animals_training &lt;- training(animals_split)
animals_testing &lt;- testing(animals_split)
```

---

class: inverse

# What mistake have we made already?

<div class="countdown" id="timer_5f7ffae8" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

class: inverse

# What mistake have we made already?

## We did EDA on the whole dataset

## By not restricting to training set =&gt; data leakage


---

# Which of these variables can we use?


```r
names(animals)
```

```
## [1] "text"        "diet"        "lifestyle"   "mean_weight"
```

---

# Feature selection checklist

--


- Is it ethical to use this variable? (or even legal?)


--


- Will this variable be available at prediction time?


--


- Does this variable contribute to explainability?

---

## variables

Response: `diet`

Categorical: `lifecycle`

Numeric: `mean_weight`

Text: `text`

---

# Categorical: lifestyle

--

.pull-left[

```r
animals_training %&gt;%
  count(lifestyle) %&gt;%
  ggplot(aes(n, lifestyle)) +
  geom_col()
```
]

.pull-right[
&lt;img src="index_files/figure-html/unnamed-chunk-15-1.png" width="700px" style="display: block; margin: auto;" /&gt;
]

---

# How should we deal with lifestyle?

- Missing values
- many categories

<div class="countdown" id="timer_5f7ffaaa" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# recipes

Flexible and reproducible preprocessing framework

---

# How to build a recipe

1. Start the recipe()
2. Define the variables involved
3. Describe preprocessing step-by-step

---

# recipe()

Creates a recipe for a set of variables


```r
recipe(reponse ~ ., data = data_set)
```

---

# recipe()

Creates a recipe for a set of variables


```r
recipe(diet ~ text + lifestyle + mean_weight, data = animals_training)
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
```

---

# step_*()

Complete list at https://recipes.tidymodels.org/reference/

---

# lifestyle steps

`step_unknown()` will replace missing values with `unknown` level


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  prep()

rec_spec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
## 
## Training data contained 459 data points and 163 incomplete rows. 
## 
## Operations:
## 
## Unknown factor level assignment for lifestyle [trained]
```

---

# lifestyle steps

`step_other()` will pool together low frequency values

---

## Your turn #5

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(___, threshold = ___)

rec_spec %&gt;%
  tidy(2)
```

---

## Your turn #5 - result

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.05)

rec_spec %&gt;%
  prep() %&gt;%
  tidy()
```

```
## # A tibble: 2 x 6
##   number operation type    trained skip  id           
##    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;        
## 1      1 step      unknown TRUE    FALSE unknown_MPxQI
## 2      2 step      other   TRUE    FALSE other_5rk3G
```

---

## Your turn #5 - result

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.05) 

rec_spec %&gt;%
  prep() %&gt;%
  tidy(2)
```

```
## # A tibble: 4 x 3
##   terms     retained id         
##   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;      
## 1 lifestyle Diurnal  other_ZlPtG
## 2 lifestyle Herd     other_ZlPtG
## 3 lifestyle Solitary other_ZlPtG
## 4 lifestyle unknown  other_ZlPtG
```

---

## Your turn #5 - result

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.1) %&gt;%
  prep()

rec_spec %&gt;%
  tidy(2)
```

```
## # A tibble: 2 x 3
##   terms     retained id         
##   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;      
## 1 lifestyle Solitary other_JJkIG
## 2 lifestyle unknown  other_JJkIG
```

---

## Your turn #5 - result

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.01) %&gt;%
  prep()

rec_spec %&gt;%
  tidy(2)
```

```
## # A tibble: 11 x 3
##    terms     retained    id         
##    &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;      
##  1 lifestyle Colony      other_BR8sj
##  2 lifestyle Crepuscular other_BR8sj
##  3 lifestyle Diurnal     other_BR8sj
##  4 lifestyle Flock       other_BR8sj
##  5 lifestyle Group       other_BR8sj
##  6 lifestyle Herd        other_BR8sj
##  7 lifestyle Nocturnal   other_BR8sj
##  8 lifestyle Pack        other_BR8sj
##  9 lifestyle Solitary    other_BR8sj
## 10 lifestyle Troop       other_BR8sj
## 11 lifestyle unknown     other_BR8sj
```

---

## Dummifying

Specify variables and play around with the threshold, default is 0.05


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.01) %&gt;%
  step_dummy(lifestyle)

rec_spec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
## 
## Operations:
## 
## Unknown factor level assignment for lifestyle
## Collapsing factor levels for lifestyle
## Dummy variables from lifestyle
```

---

# Numeric - mean_weight


```r
animals_training %&gt;%
  ggplot(aes(mean_weight)) +
  geom_histogram()
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

```
## Warning: Removed 97 rows containing non-finite values (stat_bin).
```

&lt;img src="index_files/figure-html/unnamed-chunk-26-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

# Numeric - mean_weight


```r
animals_training %&gt;%
  ggplot(aes(mean_weight)) +
  geom_histogram() +
  scale_x_log10()
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

```
## Warning: Removed 97 rows containing non-finite values (stat_bin).
```

&lt;img src="index_files/figure-html/unnamed-chunk-27-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.01) %&gt;%
  step_dummy(lifestyle) %&gt;%
  step_log(mean_weight) %&gt;%
  step_meanimpute(mean_weight)
```

---

# Text preprocessing workflow

- turn text into tokens
- modify/filter tokens
- count tokens

---

# Text preprocessing workflow - tokenize


```r
recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
## 
## Operations:
## 
## Tokenization for text
## Stop word removal for text
## Text filtering for text
## Term frequency with text
```

---

# Text preprocessing workflow - modify tokens


```r
recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
## 
## Operations:
## 
## Tokenization for text
## Stop word removal for text
## Text filtering for text
## Term frequency with text
```

---

# Text preprocessing workflow - count tokens


```r
recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
## 
## Operations:
## 
## Tokenization for text
## Stop word removal for text
## Text filtering for text
## Term frequency with text
```

---

# Your turn #6

play around with the arguments in step_tokenfilter() and see what results we get


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

<div class="countdown" id="timer_5f7ffcca" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Your turn #6 - result

play around with the arguments in step_tokenfilter() and see what results we get


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

```
## # A tibble: 459 x 103
##    lifestyle mean_weight diet  tf_text_able tf_text_africa tf_text_african
##    &lt;fct&gt;           &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;
##  1 Nocturnal       70    Omniâ€¦            7              3               1
##  2 &lt;NA&gt;            NA    Unknâ€¦            0              1               1
##  3 Diurnal          4.5  Carnâ€¦            4              0               0
##  4 &lt;NA&gt;            NA    Unknâ€¦            2              0               0
##  5 Diurnal       4500    Herbâ€¦            3              6              67
##  6 Nocturnal        2.95 Omniâ€¦            1              2              55
##  7 Diurnal       1950    Herbâ€¦            3              3              59
##  8 Crepuscuâ€¦        2.95 Omniâ€¦            2              3              44
##  9 Diurnal          3.5  Carnâ€¦            0              3              47
## 10 Crepuscuâ€¦       26.5  Carnâ€¦            1              4              51
## # â€¦ with 449 more rows, and 97 more variables: tf_text_along &lt;dbl&gt;,
## #   tf_text_also &lt;dbl&gt;, tf_text_although &lt;dbl&gt;, tf_text_animal &lt;dbl&gt;,
## #   tf_text_animals &lt;dbl&gt;, tf_text_appearance &lt;dbl&gt;, tf_text_areas &lt;dbl&gt;,
## #   tf_text_around &lt;dbl&gt;, tf_text_bear &lt;dbl&gt;, tf_text_birds &lt;dbl&gt;,
## #   tf_text_birth &lt;dbl&gt;, tf_text_black &lt;dbl&gt;, tf_text_body &lt;dbl&gt;,
## #   tf_text_breed &lt;dbl&gt;, tf_text_can &lt;dbl&gt;, tf_text_common &lt;dbl&gt;,
## #   tf_text_despite &lt;dbl&gt;, tf_text_diet &lt;dbl&gt;, tf_text_different &lt;dbl&gt;,
## #   tf_text_dog &lt;dbl&gt;, tf_text_due &lt;dbl&gt;, tf_text_eat &lt;dbl&gt;,
## #   tf_text_eggs &lt;dbl&gt;, tf_text_elephant &lt;dbl&gt;, tf_text_even &lt;dbl&gt;,
## #   tf_text_fact &lt;dbl&gt;, tf_text_feet &lt;dbl&gt;, tf_text_female &lt;dbl&gt;,
## #   tf_text_females &lt;dbl&gt;, tf_text_fish &lt;dbl&gt;, tf_text_food &lt;dbl&gt;,
## #   tf_text_found &lt;dbl&gt;, tf_text_fur &lt;dbl&gt;, tf_text_generally &lt;dbl&gt;,
## #   tf_text_habitat &lt;dbl&gt;, tf_text_however &lt;dbl&gt;, tf_text_human &lt;dbl&gt;,
## #   tf_text_humans &lt;dbl&gt;, tf_text_hunt &lt;dbl&gt;, tf_text_hunting &lt;dbl&gt;,
## #   tf_text_including &lt;dbl&gt;, tf_text_insects &lt;dbl&gt;, tf_text_just &lt;dbl&gt;,
## #   tf_text_known &lt;dbl&gt;, tf_text_large &lt;dbl&gt;, tf_text_larger &lt;dbl&gt;,
## #   tf_text_life &lt;dbl&gt;, tf_text_like &lt;dbl&gt;, tf_text_live &lt;dbl&gt;,
## #   tf_text_long &lt;dbl&gt;, tf_text_make &lt;dbl&gt;, tf_text_male &lt;dbl&gt;,
## #   tf_text_males &lt;dbl&gt;, tf_text_many &lt;dbl&gt;, tf_text_may &lt;dbl&gt;,
## #   tf_text_means &lt;dbl&gt;, tf_text_monkey &lt;dbl&gt;, tf_text_months &lt;dbl&gt;,
## #   tf_text_much &lt;dbl&gt;, tf_text_name &lt;dbl&gt;, tf_text_natural &lt;dbl&gt;,
## #   tf_text_number &lt;dbl&gt;, tf_text_often &lt;dbl&gt;, tf_text_old &lt;dbl&gt;,
## #   tf_text_one &lt;dbl&gt;, tf_text_penguin &lt;dbl&gt;, tf_text_people &lt;dbl&gt;,
## #   tf_text_population &lt;dbl&gt;, tf_text_populations &lt;dbl&gt;,
## #   tf_text_predators &lt;dbl&gt;, tf_text_prey &lt;dbl&gt;, tf_text_range &lt;dbl&gt;,
## #   tf_text_rhino &lt;dbl&gt;, tf_text_sea &lt;dbl&gt;, tf_text_size &lt;dbl&gt;,
## #   tf_text_small &lt;dbl&gt;, tf_text_smaller &lt;dbl&gt;, tf_text_south &lt;dbl&gt;,
## #   tf_text_species &lt;dbl&gt;, tf_text_tend &lt;dbl&gt;, tf_text_thought &lt;dbl&gt;,
## #   tf_text_three &lt;dbl&gt;, tf_text_throughout &lt;dbl&gt;, tf_text_tiger &lt;dbl&gt;,
## #   tf_text_time &lt;dbl&gt;, tf_text_today &lt;dbl&gt;, tf_text_trees &lt;dbl&gt;,
## #   tf_text_two &lt;dbl&gt;, tf_text_usually &lt;dbl&gt;, tf_text_water &lt;dbl&gt;,
## #   tf_text_well &lt;dbl&gt;, tf_text_white &lt;dbl&gt;, tf_text_wild &lt;dbl&gt;,
## #   tf_text_world &lt;dbl&gt;, tf_text_year &lt;dbl&gt;, tf_text_years &lt;dbl&gt;,
## #   tf_text_young &lt;dbl&gt;
```

---

# Your turn #6 - result

If we don't filter the tokens then we get a very large number of columns


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  #step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

```
## # A tibble: 459 x 14,347
##    lifestyle mean_weight diet  tf_text_0.2 tf_text_0.24 tf_text_0.5
##    &lt;fct&gt;           &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
##  1 Nocturnal       70    Omniâ€¦           0            0           0
##  2 &lt;NA&gt;            NA    Unknâ€¦           0            0           0
##  3 Diurnal          4.5  Carnâ€¦           0            0           0
##  4 &lt;NA&gt;            NA    Unknâ€¦           0            0           0
##  5 Diurnal       4500    Herbâ€¦           0            0           0
##  6 Nocturnal        2.95 Omniâ€¦           0            0           0
##  7 Diurnal       1950    Herbâ€¦           0            0           0
##  8 Crepuscuâ€¦        2.95 Omniâ€¦           0            0           0
##  9 Diurnal          3.5  Carnâ€¦           0            0           0
## 10 Crepuscuâ€¦       26.5  Carnâ€¦           0            0           0
## # â€¦ with 449 more rows, and 14,341 more variables: tf_text_0.5cm &lt;dbl&gt;,
## #   tf_text_0.6 &lt;dbl&gt;, tf_text_0.7 &lt;dbl&gt;, tf_text_0.88 &lt;dbl&gt;,
## #   tf_text_0.9 &lt;dbl&gt;, tf_text_011 &lt;dbl&gt;, tf_text_014 &lt;dbl&gt;, tf_text_053 &lt;dbl&gt;,
## #   tf_text_07 &lt;dbl&gt;, tf_text_071 &lt;dbl&gt;, tf_text_1 &lt;dbl&gt;,
## #   `tf_text_1,000` &lt;dbl&gt;, `tf_text_1,000,000` &lt;dbl&gt;, `tf_text_1,000kg` &lt;dbl&gt;,
## #   `tf_text_1,000km` &lt;dbl&gt;, `tf_text_1,037` &lt;dbl&gt;, `tf_text_1,100` &lt;dbl&gt;,
## #   `tf_text_1,175` &lt;dbl&gt;, `tf_text_1,200` &lt;dbl&gt;, `tf_text_1,200,000` &lt;dbl&gt;,
## #   `tf_text_1,215` &lt;dbl&gt;, `tf_text_1,300` &lt;dbl&gt;, `tf_text_1,300m` &lt;dbl&gt;,
## #   `tf_text_1,360` &lt;dbl&gt;, `tf_text_1,400` &lt;dbl&gt;, `tf_text_1,440` &lt;dbl&gt;,
## #   `tf_text_1,500` &lt;dbl&gt;, `tf_text_1,500m` &lt;dbl&gt;, `tf_text_1,600` &lt;dbl&gt;,
## #   `tf_text_1,700` &lt;dbl&gt;, `tf_text_1,760` &lt;dbl&gt;, `tf_text_1,800` &lt;dbl&gt;,
## #   tf_text_1.1 &lt;dbl&gt;, tf_text_1.17 &lt;dbl&gt;, tf_text_1.2 &lt;dbl&gt;,
## #   tf_text_1.3 &lt;dbl&gt;, tf_text_1.4 &lt;dbl&gt;, tf_text_1.5 &lt;dbl&gt;,
## #   tf_text_1.5cm &lt;dbl&gt;, tf_text_1.5kg &lt;dbl&gt;, tf_text_1.5m &lt;dbl&gt;,
## #   tf_text_1.6 &lt;dbl&gt;, tf_text_1.7 &lt;dbl&gt;, tf_text_1.8 &lt;dbl&gt;, tf_text_1.9 &lt;dbl&gt;,
## #   tf_text_10 &lt;dbl&gt;, `tf_text_10,000` &lt;dbl&gt;, tf_text_10.4 &lt;dbl&gt;,
## #   tf_text_10.5 &lt;dbl&gt;, tf_text_100 &lt;dbl&gt;, `tf_text_100,000` &lt;dbl&gt;,
## #   tf_text_1000 &lt;dbl&gt;, tf_text_100cm &lt;dbl&gt;, tf_text_100ft &lt;dbl&gt;,
## #   tf_text_100kg &lt;dbl&gt;, tf_text_100km &lt;dbl&gt;, tf_text_100m &lt;dbl&gt;,
## #   tf_text_102 &lt;dbl&gt;, tf_text_103 &lt;dbl&gt;, tf_text_104 &lt;dbl&gt;, tf_text_105 &lt;dbl&gt;,
## #   tf_text_107 &lt;dbl&gt;, tf_text_10cm &lt;dbl&gt;, tf_text_10kg &lt;dbl&gt;,
## #   tf_text_10km &lt;dbl&gt;, tf_text_11 &lt;dbl&gt;, `tf_text_11,000` &lt;dbl&gt;,
## #   tf_text_110 &lt;dbl&gt;, `tf_text_110,000` &lt;dbl&gt;, tf_text_110cm &lt;dbl&gt;,
## #   tf_text_112 &lt;dbl&gt;, tf_text_114 &lt;dbl&gt;, tf_text_116 &lt;dbl&gt;, tf_text_119 &lt;dbl&gt;,
## #   tf_text_11mph &lt;dbl&gt;, tf_text_12 &lt;dbl&gt;, `tf_text_12,000` &lt;dbl&gt;,
## #   tf_text_12.6 &lt;dbl&gt;, tf_text_120 &lt;dbl&gt;, `tf_text_120,000` &lt;dbl&gt;,
## #   tf_text_1200 &lt;dbl&gt;, tf_text_120g &lt;dbl&gt;, tf_text_124 &lt;dbl&gt;,
## #   tf_text_124.2 &lt;dbl&gt;, tf_text_125 &lt;dbl&gt;, tf_text_126 &lt;dbl&gt;,
## #   `tf_text_127,000` &lt;dbl&gt;, tf_text_129 &lt;dbl&gt;, tf_text_12th &lt;dbl&gt;,
## #   tf_text_13 &lt;dbl&gt;, `tf_text_13,000` &lt;dbl&gt;, `tf_text_13,800` &lt;dbl&gt;,
## #   tf_text_13.2 &lt;dbl&gt;, tf_text_13.5 &lt;dbl&gt;, tf_text_130 &lt;dbl&gt;,
## #   `tf_text_130,000` &lt;dbl&gt;, tf_text_1300 &lt;dbl&gt;, tf_text_132 &lt;dbl&gt;,
## #   tf_text_135 &lt;dbl&gt;, tf_text_13cm &lt;dbl&gt;, â€¦
```

---

# Your turn #7

Swap `step_tf()` with `step_tfidf()` and see the change


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

<div class="countdown" id="timer_5f7ffa49" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Your turn #7 - result

Swap `step_tf()` with `step_tfidf()` and see the change


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight,
                   data = animals_training) %&gt;%
  # Tokenize to words
  step_tokenize(text) %&gt;%
  # Remove stopwords
  step_stopwords(text) %&gt;%
  # Remove less frequent words
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  # Calculate term frequencies
  step_tfidf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

```
## # A tibble: 459 x 103
##    lifestyle mean_weight diet  tfidf_text_able tfidf_text_afriâ€¦ tfidf_text_afriâ€¦
##    &lt;fct&gt;           &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1 Nocturnal       70    Omniâ€¦         0.0433            0.0252           0.0104
##  2 &lt;NA&gt;            NA    Unknâ€¦         0                 0.0310           0.0382
##  3 Diurnal          4.5  Carnâ€¦         0.0249            0                0     
##  4 &lt;NA&gt;            NA    Unknâ€¦         0.0329            0                0     
##  5 Diurnal       4500    Herbâ€¦         0.0127            0.0344           0.473 
##  6 Nocturnal        2.95 Omniâ€¦         0.00595           0.0162           0.548 
##  7 Diurnal       1950    Herbâ€¦         0.0163            0.0221           0.536 
##  8 Crepuscuâ€¦        2.95 Omniâ€¦         0.0114            0.0231           0.418 
##  9 Diurnal          3.5  Carnâ€¦         0                 0.0175           0.337 
## 10 Crepuscuâ€¦       26.5  Carnâ€¦         0.00401           0.0218           0.342 
## # â€¦ with 449 more rows, and 97 more variables: tfidf_text_along &lt;dbl&gt;,
## #   tfidf_text_also &lt;dbl&gt;, tfidf_text_although &lt;dbl&gt;, tfidf_text_animal &lt;dbl&gt;,
## #   tfidf_text_animals &lt;dbl&gt;, tfidf_text_appearance &lt;dbl&gt;,
## #   tfidf_text_areas &lt;dbl&gt;, tfidf_text_around &lt;dbl&gt;, tfidf_text_bear &lt;dbl&gt;,
## #   tfidf_text_birds &lt;dbl&gt;, tfidf_text_birth &lt;dbl&gt;, tfidf_text_black &lt;dbl&gt;,
## #   tfidf_text_body &lt;dbl&gt;, tfidf_text_breed &lt;dbl&gt;, tfidf_text_can &lt;dbl&gt;,
## #   tfidf_text_common &lt;dbl&gt;, tfidf_text_despite &lt;dbl&gt;, tfidf_text_diet &lt;dbl&gt;,
## #   tfidf_text_different &lt;dbl&gt;, tfidf_text_dog &lt;dbl&gt;, tfidf_text_due &lt;dbl&gt;,
## #   tfidf_text_eat &lt;dbl&gt;, tfidf_text_eggs &lt;dbl&gt;, tfidf_text_elephant &lt;dbl&gt;,
## #   tfidf_text_even &lt;dbl&gt;, tfidf_text_fact &lt;dbl&gt;, tfidf_text_feet &lt;dbl&gt;,
## #   tfidf_text_female &lt;dbl&gt;, tfidf_text_females &lt;dbl&gt;, tfidf_text_fish &lt;dbl&gt;,
## #   tfidf_text_food &lt;dbl&gt;, tfidf_text_found &lt;dbl&gt;, tfidf_text_fur &lt;dbl&gt;,
## #   tfidf_text_generally &lt;dbl&gt;, tfidf_text_habitat &lt;dbl&gt;,
## #   tfidf_text_however &lt;dbl&gt;, tfidf_text_human &lt;dbl&gt;, tfidf_text_humans &lt;dbl&gt;,
## #   tfidf_text_hunt &lt;dbl&gt;, tfidf_text_hunting &lt;dbl&gt;,
## #   tfidf_text_including &lt;dbl&gt;, tfidf_text_insects &lt;dbl&gt;,
## #   tfidf_text_just &lt;dbl&gt;, tfidf_text_known &lt;dbl&gt;, tfidf_text_large &lt;dbl&gt;,
## #   tfidf_text_larger &lt;dbl&gt;, tfidf_text_life &lt;dbl&gt;, tfidf_text_like &lt;dbl&gt;,
## #   tfidf_text_live &lt;dbl&gt;, tfidf_text_long &lt;dbl&gt;, tfidf_text_make &lt;dbl&gt;,
## #   tfidf_text_male &lt;dbl&gt;, tfidf_text_males &lt;dbl&gt;, tfidf_text_many &lt;dbl&gt;,
## #   tfidf_text_may &lt;dbl&gt;, tfidf_text_means &lt;dbl&gt;, tfidf_text_monkey &lt;dbl&gt;,
## #   tfidf_text_months &lt;dbl&gt;, tfidf_text_much &lt;dbl&gt;, tfidf_text_name &lt;dbl&gt;,
## #   tfidf_text_natural &lt;dbl&gt;, tfidf_text_number &lt;dbl&gt;, tfidf_text_often &lt;dbl&gt;,
## #   tfidf_text_old &lt;dbl&gt;, tfidf_text_one &lt;dbl&gt;, tfidf_text_penguin &lt;dbl&gt;,
## #   tfidf_text_people &lt;dbl&gt;, tfidf_text_population &lt;dbl&gt;,
## #   tfidf_text_populations &lt;dbl&gt;, tfidf_text_predators &lt;dbl&gt;,
## #   tfidf_text_prey &lt;dbl&gt;, tfidf_text_range &lt;dbl&gt;, tfidf_text_rhino &lt;dbl&gt;,
## #   tfidf_text_sea &lt;dbl&gt;, tfidf_text_size &lt;dbl&gt;, tfidf_text_small &lt;dbl&gt;,
## #   tfidf_text_smaller &lt;dbl&gt;, tfidf_text_south &lt;dbl&gt;, tfidf_text_species &lt;dbl&gt;,
## #   tfidf_text_tend &lt;dbl&gt;, tfidf_text_thought &lt;dbl&gt;, tfidf_text_three &lt;dbl&gt;,
## #   tfidf_text_throughout &lt;dbl&gt;, tfidf_text_tiger &lt;dbl&gt;, tfidf_text_time &lt;dbl&gt;,
## #   tfidf_text_today &lt;dbl&gt;, tfidf_text_trees &lt;dbl&gt;, tfidf_text_two &lt;dbl&gt;,
## #   tfidf_text_usually &lt;dbl&gt;, tfidf_text_water &lt;dbl&gt;, tfidf_text_well &lt;dbl&gt;,
## #   tfidf_text_white &lt;dbl&gt;, tfidf_text_wild &lt;dbl&gt;, tfidf_text_world &lt;dbl&gt;,
## #   tfidf_text_year &lt;dbl&gt;, tfidf_text_years &lt;dbl&gt;, tfidf_text_young &lt;dbl&gt;
```

---

# Your turn #8

Insert `step_ngram()` into recipe after tokenization. Play around with `num_tokens = ` and `min_num_tokens = `


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight,
                   data = animals_training) %&gt;%
  step_tokenize(text) %&gt;%
  step_stopwords(text) %&gt;%
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  step_tfidf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice()
```

```
## # A tibble: 459 x 103
##    lifestyle mean_weight diet  tfidf_text_able tfidf_text_afriâ€¦ tfidf_text_afriâ€¦
##    &lt;fct&gt;           &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1 Nocturnal       70    Omniâ€¦         0.0433            0.0252           0.0104
##  2 &lt;NA&gt;            NA    Unknâ€¦         0                 0.0310           0.0382
##  3 Diurnal          4.5  Carnâ€¦         0.0249            0                0     
##  4 &lt;NA&gt;            NA    Unknâ€¦         0.0329            0                0     
##  5 Diurnal       4500    Herbâ€¦         0.0127            0.0344           0.473 
##  6 Nocturnal        2.95 Omniâ€¦         0.00595           0.0162           0.548 
##  7 Diurnal       1950    Herbâ€¦         0.0163            0.0221           0.536 
##  8 Crepuscuâ€¦        2.95 Omniâ€¦         0.0114            0.0231           0.418 
##  9 Diurnal          3.5  Carnâ€¦         0                 0.0175           0.337 
## 10 Crepuscuâ€¦       26.5  Carnâ€¦         0.00401           0.0218           0.342 
## # â€¦ with 449 more rows, and 97 more variables: tfidf_text_along &lt;dbl&gt;,
## #   tfidf_text_also &lt;dbl&gt;, tfidf_text_although &lt;dbl&gt;, tfidf_text_animal &lt;dbl&gt;,
## #   tfidf_text_animals &lt;dbl&gt;, tfidf_text_appearance &lt;dbl&gt;,
## #   tfidf_text_areas &lt;dbl&gt;, tfidf_text_around &lt;dbl&gt;, tfidf_text_bear &lt;dbl&gt;,
## #   tfidf_text_birds &lt;dbl&gt;, tfidf_text_birth &lt;dbl&gt;, tfidf_text_black &lt;dbl&gt;,
## #   tfidf_text_body &lt;dbl&gt;, tfidf_text_breed &lt;dbl&gt;, tfidf_text_can &lt;dbl&gt;,
## #   tfidf_text_common &lt;dbl&gt;, tfidf_text_despite &lt;dbl&gt;, tfidf_text_diet &lt;dbl&gt;,
## #   tfidf_text_different &lt;dbl&gt;, tfidf_text_dog &lt;dbl&gt;, tfidf_text_due &lt;dbl&gt;,
## #   tfidf_text_eat &lt;dbl&gt;, tfidf_text_eggs &lt;dbl&gt;, tfidf_text_elephant &lt;dbl&gt;,
## #   tfidf_text_even &lt;dbl&gt;, tfidf_text_fact &lt;dbl&gt;, tfidf_text_feet &lt;dbl&gt;,
## #   tfidf_text_female &lt;dbl&gt;, tfidf_text_females &lt;dbl&gt;, tfidf_text_fish &lt;dbl&gt;,
## #   tfidf_text_food &lt;dbl&gt;, tfidf_text_found &lt;dbl&gt;, tfidf_text_fur &lt;dbl&gt;,
## #   tfidf_text_generally &lt;dbl&gt;, tfidf_text_habitat &lt;dbl&gt;,
## #   tfidf_text_however &lt;dbl&gt;, tfidf_text_human &lt;dbl&gt;, tfidf_text_humans &lt;dbl&gt;,
## #   tfidf_text_hunt &lt;dbl&gt;, tfidf_text_hunting &lt;dbl&gt;,
## #   tfidf_text_including &lt;dbl&gt;, tfidf_text_insects &lt;dbl&gt;,
## #   tfidf_text_just &lt;dbl&gt;, tfidf_text_known &lt;dbl&gt;, tfidf_text_large &lt;dbl&gt;,
## #   tfidf_text_larger &lt;dbl&gt;, tfidf_text_life &lt;dbl&gt;, tfidf_text_like &lt;dbl&gt;,
## #   tfidf_text_live &lt;dbl&gt;, tfidf_text_long &lt;dbl&gt;, tfidf_text_make &lt;dbl&gt;,
## #   tfidf_text_male &lt;dbl&gt;, tfidf_text_males &lt;dbl&gt;, tfidf_text_many &lt;dbl&gt;,
## #   tfidf_text_may &lt;dbl&gt;, tfidf_text_means &lt;dbl&gt;, tfidf_text_monkey &lt;dbl&gt;,
## #   tfidf_text_months &lt;dbl&gt;, tfidf_text_much &lt;dbl&gt;, tfidf_text_name &lt;dbl&gt;,
## #   tfidf_text_natural &lt;dbl&gt;, tfidf_text_number &lt;dbl&gt;, tfidf_text_often &lt;dbl&gt;,
## #   tfidf_text_old &lt;dbl&gt;, tfidf_text_one &lt;dbl&gt;, tfidf_text_penguin &lt;dbl&gt;,
## #   tfidf_text_people &lt;dbl&gt;, tfidf_text_population &lt;dbl&gt;,
## #   tfidf_text_populations &lt;dbl&gt;, tfidf_text_predators &lt;dbl&gt;,
## #   tfidf_text_prey &lt;dbl&gt;, tfidf_text_range &lt;dbl&gt;, tfidf_text_rhino &lt;dbl&gt;,
## #   tfidf_text_sea &lt;dbl&gt;, tfidf_text_size &lt;dbl&gt;, tfidf_text_small &lt;dbl&gt;,
## #   tfidf_text_smaller &lt;dbl&gt;, tfidf_text_south &lt;dbl&gt;, tfidf_text_species &lt;dbl&gt;,
## #   tfidf_text_tend &lt;dbl&gt;, tfidf_text_thought &lt;dbl&gt;, tfidf_text_three &lt;dbl&gt;,
## #   tfidf_text_throughout &lt;dbl&gt;, tfidf_text_tiger &lt;dbl&gt;, tfidf_text_time &lt;dbl&gt;,
## #   tfidf_text_today &lt;dbl&gt;, tfidf_text_trees &lt;dbl&gt;, tfidf_text_two &lt;dbl&gt;,
## #   tfidf_text_usually &lt;dbl&gt;, tfidf_text_water &lt;dbl&gt;, tfidf_text_well &lt;dbl&gt;,
## #   tfidf_text_white &lt;dbl&gt;, tfidf_text_wild &lt;dbl&gt;, tfidf_text_world &lt;dbl&gt;,
## #   tfidf_text_year &lt;dbl&gt;, tfidf_text_years &lt;dbl&gt;, tfidf_text_young &lt;dbl&gt;
```

<div class="countdown" id="timer_5f7ffca3" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">03</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Your turn #8 - result

Insert `step_ngram()` into recipe after tokenization. Play around with `num_tokens = ` and `min_num_tokens = `


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight,
                   data = animals_training) %&gt;%
  step_tokenize(text) %&gt;%
  step_ngram(text, min_num_tokens = 1, num_tokens = 2) %&gt;%
  step_stopwords(text) %&gt;%
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  step_tfidf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice() %&gt;%
  names()
```

```
##   [1] "lifestyle"             "mean_weight"           "diet"                 
##   [4] "tfidf_text_able"       "tfidf_text_able_to"    "tfidf_text_african"   
##   [7] "tfidf_text_along"      "tfidf_text_also"       "tfidf_text_although"  
##  [10] "tfidf_text_and_the"    "tfidf_text_animal"     "tfidf_text_animals"   
##  [13] "tfidf_text_are_also"   "tfidf_text_areas"      "tfidf_text_around"    
##  [16] "tfidf_text_as_a"       "tfidf_text_as_the"     "tfidf_text_birds"     
##  [19] "tfidf_text_black"      "tfidf_text_body"       "tfidf_text_can"       
##  [22] "tfidf_text_common"     "tfidf_text_diet"       "tfidf_text_different" 
##  [25] "tfidf_text_due"        "tfidf_text_due_to"     "tfidf_text_eat"       
##  [28] "tfidf_text_eggs"       "tfidf_text_even"       "tfidf_text_female"    
##  [31] "tfidf_text_females"    "tfidf_text_fish"       "tfidf_text_food"      
##  [34] "tfidf_text_for_the"    "tfidf_text_found"      "tfidf_text_found_in"  
##  [37] "tfidf_text_from_the"   "tfidf_text_habitat"    "tfidf_text_have_been" 
##  [40] "tfidf_text_however"    "tfidf_text_humans"     "tfidf_text_in_a"      
##  [43] "tfidf_text_in_the"     "tfidf_text_including"  "tfidf_text_is_a"      
##  [46] "tfidf_text_is_the"     "tfidf_text_it_is"      "tfidf_text_known"     
##  [49] "tfidf_text_known_to"   "tfidf_text_large"      "tfidf_text_like"      
##  [52] "tfidf_text_live"       "tfidf_text_long"       "tfidf_text_male"      
##  [55] "tfidf_text_males"      "tfidf_text_many"       "tfidf_text_may"       
##  [58] "tfidf_text_months"     "tfidf_text_much"       "tfidf_text_name"      
##  [61] "tfidf_text_natural"    "tfidf_text_of_a"       "tfidf_text_of_the"    
##  [64] "tfidf_text_of_their"   "tfidf_text_often"      "tfidf_text_old"       
##  [67] "tfidf_text_on_the"     "tfidf_text_one"        "tfidf_text_one_of"    
##  [70] "tfidf_text_penguin"    "tfidf_text_population" "tfidf_text_predators" 
##  [73] "tfidf_text_prey"       "tfidf_text_range"      "tfidf_text_sea"       
##  [76] "tfidf_text_size"       "tfidf_text_small"      "tfidf_text_species"   
##  [79] "tfidf_text_species_of" "tfidf_text_such_as"    "tfidf_text_that_are"  
##  [82] "tfidf_text_that_they"  "tfidf_text_the_water"  "tfidf_text_the_wild"  
##  [85] "tfidf_text_the_world"  "tfidf_text_there_are"  "tfidf_text_they_are"  
##  [88] "tfidf_text_thought"    "tfidf_text_throughout" "tfidf_text_time"      
##  [91] "tfidf_text_to_be"      "tfidf_text_to_the"     "tfidf_text_today"     
##  [94] "tfidf_text_two"        "tfidf_text_up_to"      "tfidf_text_water"     
##  [97] "tfidf_text_well"       "tfidf_text_white"      "tfidf_text_wild"      
## [100] "tfidf_text_with_the"   "tfidf_text_world"      "tfidf_text_years"     
## [103] "tfidf_text_young"
```

---

# Your turn #8 - result

Order matters!


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight,
                   data = animals_training) %&gt;%
  step_tokenize(text) %&gt;%
  step_stopwords(text) %&gt;%
  step_ngram(text, min_num_tokens = 1, num_tokens = 2) %&gt;%
  step_tokenfilter(text, max_tokens = 100) %&gt;%
  step_tfidf(text)

rec_spec %&gt;%
  prep() %&gt;%
  juice() %&gt;%
  names()
```

```
##   [1] "lifestyle"              "mean_weight"            "diet"                  
##   [4] "tfidf_text_able"        "tfidf_text_africa"      "tfidf_text_african"    
##   [7] "tfidf_text_along"       "tfidf_text_also"        "tfidf_text_although"   
##  [10] "tfidf_text_animal"      "tfidf_text_animals"     "tfidf_text_appearance" 
##  [13] "tfidf_text_areas"       "tfidf_text_around"      "tfidf_text_bear"       
##  [16] "tfidf_text_birds"       "tfidf_text_birth"       "tfidf_text_black"      
##  [19] "tfidf_text_body"        "tfidf_text_breed"       "tfidf_text_can"        
##  [22] "tfidf_text_common"      "tfidf_text_despite"     "tfidf_text_diet"       
##  [25] "tfidf_text_different"   "tfidf_text_dog"         "tfidf_text_due"        
##  [28] "tfidf_text_eat"         "tfidf_text_eggs"        "tfidf_text_elephant"   
##  [31] "tfidf_text_even"        "tfidf_text_fact"        "tfidf_text_feet"       
##  [34] "tfidf_text_female"      "tfidf_text_females"     "tfidf_text_fish"       
##  [37] "tfidf_text_food"        "tfidf_text_found"       "tfidf_text_fur"        
##  [40] "tfidf_text_generally"   "tfidf_text_habitat"     "tfidf_text_however"    
##  [43] "tfidf_text_human"       "tfidf_text_humans"      "tfidf_text_hunt"       
##  [46] "tfidf_text_hunting"     "tfidf_text_including"   "tfidf_text_insects"    
##  [49] "tfidf_text_just"        "tfidf_text_known"       "tfidf_text_large"      
##  [52] "tfidf_text_larger"      "tfidf_text_life"        "tfidf_text_like"       
##  [55] "tfidf_text_live"        "tfidf_text_long"        "tfidf_text_make"       
##  [58] "tfidf_text_male"        "tfidf_text_males"       "tfidf_text_many"       
##  [61] "tfidf_text_may"         "tfidf_text_means"       "tfidf_text_monkey"     
##  [64] "tfidf_text_months"      "tfidf_text_much"        "tfidf_text_name"       
##  [67] "tfidf_text_natural"     "tfidf_text_number"      "tfidf_text_often"      
##  [70] "tfidf_text_old"         "tfidf_text_one"         "tfidf_text_penguin"    
##  [73] "tfidf_text_people"      "tfidf_text_population"  "tfidf_text_populations"
##  [76] "tfidf_text_predators"   "tfidf_text_prey"        "tfidf_text_range"      
##  [79] "tfidf_text_rhino"       "tfidf_text_sea"         "tfidf_text_size"       
##  [82] "tfidf_text_small"       "tfidf_text_smaller"     "tfidf_text_south"      
##  [85] "tfidf_text_species"     "tfidf_text_tend"        "tfidf_text_thought"    
##  [88] "tfidf_text_three"       "tfidf_text_throughout"  "tfidf_text_tiger"      
##  [91] "tfidf_text_time"        "tfidf_text_today"       "tfidf_text_trees"      
##  [94] "tfidf_text_two"         "tfidf_text_usually"     "tfidf_text_water"      
##  [97] "tfidf_text_well"        "tfidf_text_white"       "tfidf_text_wild"       
## [100] "tfidf_text_world"       "tfidf_text_year"        "tfidf_text_years"      
## [103] "tfidf_text_young"
```

---

# Final recipe


```r
rec_spec &lt;- recipe(diet ~ text + lifestyle + mean_weight, 
                   data = animals_training) %&gt;%
  step_unknown(lifestyle) %&gt;%
  step_other(lifestyle, threshold = 0.01) %&gt;%
  step_dummy(lifestyle) %&gt;%
  step_log(mean_weight) %&gt;%
  step_meanimpute(mean_weight) %&gt;%
  step_tokenize(text) %&gt;%
  step_tokenfilter(text, max_tokens = tune()) %&gt;%
  step_tfidf(text)
```

Also, what does `tune()` mean here? ðŸ¤”

---

class: inverse, right, middle

## What kind of **models** work well for text?

---

# Text models

Remember that text data is sparse! ðŸ˜®

--


- Regularized linear models (glmnet)
- Support vector machines
- naive Bayes
- Tree-based models like random forest? 

---

# Text models

Remember that text data is sparse! ðŸ˜®

- Regularized linear models (glmnet)
- Support vector machines
- naive Bayes
- Tree-based models like random forest?  ðŸ™…

---

class: inverse, right, middle

# Does text data have to be **sparse**?

---


&gt;### You shall know a word by the company it keeps.
#### [ðŸ’¬ John Rupert Firth](https://en.wikiquote.org/wiki/John_Rupert_Firth)



--

Learn more about word embeddings:

- in [Chapter 5](https://smltar.com/embeddings.html)
- at [juliasilge.github.io/why-r-webinar/](https://juliasilge.github.io/why-r-webinar/)


---

# To specify a model in tidymodels

1\. Pick a **model**

2\. Set the **mode** (if needed)

3\. Set the **engine**

---

background-image: url(https://github.com/allisonhorst/stats-illustrations/raw/master/rstats-artwork/parsnip.png)
background-size: cover

.footnote[
Art by [Allison Horst](https://github.com/allisonhorst/stats-illustrations)
]

---

# To specify a model in tidymodels

All available models are listed at &lt;https://tidymodels.org/find/parsnip&gt;

&lt;iframe src="https://tidymodels.org/find/parsnip" width="100%" height="400px"&gt;&lt;/iframe&gt;

---

class: middle


# `set_mode()`

Some models can solve multiple types of problems



```r
svm_rbf() %&gt;% set_mode(mode = "regression")
```

```
## Radial Basis Function Support Vector Machine Specification (regression)
```

---

class: middle


# `set_mode()`

Some models can solve multiple types of problems



```r
svm_rbf() %&gt;% set_mode(mode = "classification")
```

```
## Radial Basis Function Support Vector Machine Specification (classification)
```

---

class: middle


# `set_engine()`

The same model can be implemented by multiple computational engines



```r
svm_rbf() %&gt;% set_engine("kernlab")
```

```
## Radial Basis Function Support Vector Machine Specification (unknown)
## 
## Computational engine: kernlab
```

---

class: middle


# `set_engine()`

The same model can be implemented by multiple computational engines



```r
svm_rbf() %&gt;% set_engine("liquidSVM")
```

```
## Radial Basis Function Support Vector Machine Specification (unknown)
## 
## Computational engine: liquidSVM
```

---

# What makes a model?


```r
lasso_spec &lt;- multinom_reg(penalty = tune(), mixture = 1) %&gt;%
  set_mode("classification") %&gt;%
  set_engine("glmnet")

lasso_spec
```

```
## Multinomial Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet
```


--

It's `tune()` again! ðŸ˜Ÿ

---

## Parameters and... hyperparameters?

- Some model parameters can be learned from data during fitting/training


--


- Some CANNOT ðŸ˜±


--


- These are **hyperparameters** of a model, and we estimate them by training lots of models with different hyperparameters and comparing them


---

# A grid of possible hyperparameters


```r
param_grid &lt;- grid_regular(
  penalty(range = c(-4, 0)),
  max_tokens(range = c(100, 500)),
  levels = c(penalty = 50, max_tokens = 4)
)
```


---

# A grid of possible hyperparameters


```
## # A tibble: 200 x 2
##     penalty max_tokens
##       &lt;dbl&gt;      &lt;int&gt;
##  1 0.0001          100
##  2 0.000121        100
##  3 0.000146        100
##  4 0.000176        100
##  5 0.000212        100
##  6 0.000256        100
##  7 0.000309        100
##  8 0.000373        100
##  9 0.000450        100
## 10 0.000543        100
## # â€¦ with 190 more rows
```

---

class: inverse, right, middle

# How can we **compare** and **evaluate** these different models?

---

background-image: url(https://www.tidymodels.org/start/resampling/img/resampling.svg)
background-size: 60%

---

# Spend your data budget


```r
set.seed(123)
animals_folds &lt;- vfold_cv(animals_training, v = 10, strata = diet)

animals_folds
```

```
## #  10-fold cross-validation using stratification 
## # A tibble: 10 x 2
##    splits           id    
##    &lt;list&gt;           &lt;chr&gt; 
##  1 &lt;split [411/48]&gt; Fold01
##  2 &lt;split [412/47]&gt; Fold02
##  3 &lt;split [412/47]&gt; Fold03
##  4 &lt;split [412/47]&gt; Fold04
##  5 &lt;split [413/46]&gt; Fold05
##  6 &lt;split [413/46]&gt; Fold06
##  7 &lt;split [414/45]&gt; Fold07
##  8 &lt;split [414/45]&gt; Fold08
##  9 &lt;split [415/44]&gt; Fold09
## 10 &lt;split [415/44]&gt; Fold10
```

---
class: middle, center, inverse

# âœ¨ CROSS-VALIDATION âœ¨

---
background-image: url(images/cross-validation/Slide2.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide3.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide4.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide5.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide6.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide7.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide8.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide9.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide10.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---
background-image: url(images/cross-validation/Slide11.png)
background-size: contain

.footnote[
Art by [Alison Hill](https://alison.rbind.io/)
]
---

class: inverse, right, middle

# Spend your data wisely to create **simulated** validation sets

---

class: inverse, right, middle

# Now we have **resamples**, **features**, plus a **model**

---

# Create a workflow


```r
wf_spec &lt;- workflow() %&gt;%
  add_recipe(rec_spec) %&gt;%
  add_model(lasso_spec)

wf_spec
```

```
## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Recipe
## Model: multinom_reg()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 8 Recipe Steps
## 
## â— step_unknown()
## â— step_other()
## â— step_dummy()
## â— step_log()
## â— step_meanimpute()
## â— step_tokenize()
## â— step_tokenfilter()
## â— step_tfidf()
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## Multinomial Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet
```

---

class: inverse, right, middle

# What is a `workflow()`?

---

## Time to tune! âš¡


```r
set.seed(42)
lasso_rs &lt;- tune_grid(
  wf_spec,
  resamples = animals_folds,
  grid = param_grid, 
  control = control_grid(save_pred = TRUE, verbose = TRUE)
) 
```

---

## Time to tune! âš¡


```
## Warning: This tuning result has notes. Example notes on model fitting include:
## recipe 1/4, model 1/1 (predictions): There are new levels in a factor: NA
## recipe 1/4, model 1/1 (predictions): There are new levels in a factor: NA
## recipe 4/4, model 1/1 (predictions): There are new levels in a factor: NA
```

```
## # Tuning results
## # 10-fold cross-validation using stratification 
## # A tibble: 10 x 5
##    splits          id     .metrics          .notes          .predictions        
##    &lt;list&gt;          &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          &lt;list&gt;              
##  1 &lt;split [411/48â€¦ Fold01 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [4 Ã— 1â€¦ &lt;tibble [9,600 Ã— 10â€¦
##  2 &lt;split [412/47â€¦ Fold02 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [0 Ã— 1â€¦ &lt;tibble [9,400 Ã— 10â€¦
##  3 &lt;split [412/47â€¦ Fold03 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [0 Ã— 1â€¦ &lt;tibble [9,400 Ã— 10â€¦
##  4 &lt;split [412/47â€¦ Fold04 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [4 Ã— 1â€¦ &lt;tibble [9,400 Ã— 10â€¦
##  5 &lt;split [413/46â€¦ Fold05 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [0 Ã— 1â€¦ &lt;tibble [9,200 Ã— 10â€¦
##  6 &lt;split [413/46â€¦ Fold06 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [4 Ã— 1â€¦ &lt;tibble [9,200 Ã— 10â€¦
##  7 &lt;split [414/45â€¦ Fold07 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [5 Ã— 1â€¦ &lt;tibble [9,000 Ã— 10â€¦
##  8 &lt;split [414/45â€¦ Fold08 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [4 Ã— 1â€¦ &lt;tibble [9,000 Ã— 10â€¦
##  9 &lt;split [415/44â€¦ Fold09 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [0 Ã— 1â€¦ &lt;tibble [8,800 Ã— 10â€¦
## 10 &lt;split [415/44â€¦ Fold10 &lt;tibble [400 Ã— 6â€¦ &lt;tibble [0 Ã— 1â€¦ &lt;tibble [8,800 Ã— 10â€¦
```

---

# Look at the tuning results ðŸ‘€



```r
collect_metrics(lasso_rs)
```

```
## # A tibble: 400 x 8
##     penalty max_tokens .metric  .estimator  mean     n std_err .config         
##       &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           
##  1 0.0001          100 accuracy multiclass 0.610    10  0.0276 Recipe1_Model001
##  2 0.0001          100 roc_auc  hand_till  0.824    10  0.0174 Recipe1_Model001
##  3 0.000121        100 accuracy multiclass 0.610    10  0.0262 Recipe1_Model002
##  4 0.000121        100 roc_auc  hand_till  0.824    10  0.0176 Recipe1_Model002
##  5 0.000146        100 accuracy multiclass 0.610    10  0.0265 Recipe1_Model003
##  6 0.000146        100 roc_auc  hand_till  0.825    10  0.0173 Recipe1_Model003
##  7 0.000176        100 accuracy multiclass 0.615    10  0.0259 Recipe1_Model004
##  8 0.000176        100 roc_auc  hand_till  0.826    10  0.0172 Recipe1_Model004
##  9 0.000212        100 accuracy multiclass 0.619    10  0.0258 Recipe1_Model005
## 10 0.000212        100 roc_auc  hand_till  0.826    10  0.0173 Recipe1_Model005
## # â€¦ with 390 more rows
```

---


```r
autoplot(lasso_rs)
```

&lt;img src="index_files/figure-html/unnamed-chunk-56-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

# Look at the tuning results ðŸ‘€


```r
lasso_rs %&gt;%
  show_best("roc_auc")
```

```
## # A tibble: 5 x 8
##   penalty max_tokens .metric .estimator  mean     n std_err .config         
##     &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           
## 1 0.0233         500 roc_auc hand_till  0.930    10  0.0109 Recipe4_Model030
## 2 0.00754        500 roc_auc hand_till  0.929    10  0.0112 Recipe4_Model024
## 3 0.0160         500 roc_auc hand_till  0.929    10  0.0106 Recipe4_Model028
## 4 0.00625        500 roc_auc hand_till  0.928    10  0.0112 Recipe4_Model023
## 5 0.0281         500 roc_auc hand_till  0.928    10  0.0112 Recipe4_Model031
```

---

# Your turn #9


Run you onw model and see what results you can find!

<div class="countdown" id="timer_5f7ffc6a" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

# The **best** ðŸ¥‡ hyperparameters 


```r
best_roc_auc &lt;- select_best(lasso_rs, "roc_auc")

best_roc_auc
```

```
## # A tibble: 1 x 3
##   penalty max_tokens .config         
##     &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;           
## 1  0.0233        500 Recipe4_Model030
```

---

# Evaluate the best model ðŸ“


```r
collect_predictions(lasso_rs, parameters = best_roc_auc)
```

```
## # A tibble: 459 x 11
##    id    .pred_Carnivore .pred_Herbivore .pred_Omnivore .pred_Unknown  .row
##    &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;
##  1 Foldâ€¦          0.857           0.0381         0.0978       0.00693     6
##  2 Foldâ€¦          0.340           0.434          0.194        0.0324      7
##  3 Foldâ€¦          0.0265          0.0304         0.0458       0.897      12
##  4 Foldâ€¦          0.556           0.146          0.259        0.0388     17
##  5 Foldâ€¦          0.870           0.0743         0.0516       0.00468    30
##  6 Foldâ€¦          0.153           0.354          0.471        0.0209     33
##  7 Foldâ€¦          0.789           0.0352         0.169        0.00651    42
##  8 Foldâ€¦          0.0767          0.119          0.623        0.182      48
##  9 Foldâ€¦          0.944           0.0108         0.0367       0.00872    49
## 10 Foldâ€¦          0.0387          0.0386         0.0613       0.861      51
## # â€¦ with 449 more rows, and 5 more variables: max_tokens &lt;int&gt;, penalty &lt;dbl&gt;,
## #   .pred_class &lt;fct&gt;, diet &lt;fct&gt;, .config &lt;chr&gt;
```

---

# Evaluate the best model ðŸ“


```r
collect_predictions(lasso_rs, parameters = best_roc_auc) %&gt;%
  roc_curve(truth = diet, .pred_Carnivore:.pred_Unknown) %&gt;%
  autoplot()
```

&lt;img src="index_files/figure-html/unnamed-chunk-61-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

# Evaluate the best model ðŸ“


```r
collect_predictions(lasso_rs, parameters = best_roc_auc) %&gt;%
  group_by(id) %&gt;%
  roc_curve(truth = diet, .pred_Carnivore:.pred_Unknown) %&gt;%
  autoplot()
```

---

# Update the workflow

We can update our workflow with the best performing hyperparameters.


```r
wf_spec_final &lt;- finalize_workflow(wf_spec, best_roc_auc)
```

This workflow is ready to go! It can now be applied to new data.

---

class: inverse, right, middle

# How is our model **thinking**?

---

## Variable importance


```r
library(vip)

wf_spec_final %&gt;%
  fit(animals_training) %&gt;%
  pull_workflow_fit() %&gt;%
  vi() %&gt;%
  filter(!str_detect(Variable, "tfidf")) %&gt;%
  filter(Importance != 0)
```

```
## # A tibble: 4 x 3
##   Variable              Importance Sign 
##   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt;
## 1 lifestyle_Pack            1.04   POS  
## 2 lifestyle_Crepuscular     0.649  POS  
## 3 lifestyle_Solitary        0.0422 POS  
## 4 lifestyle_unknown        -0.578  NEG
```

---

## Variable importance


```r
vi_data &lt;- wf_spec_final %&gt;%
  fit(animals_training) %&gt;%
  pull_workflow_fit() %&gt;%
  vi() %&gt;%
  mutate(Variable = str_remove_all(Variable, "tfidf_text_")) %&gt;%
  filter(Importance != 0)
```

---

## Variable importance 


```r
vi_data
```

```
## # A tibble: 69 x 3
##    Variable    Importance Sign 
##    &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;
##  1 carnivores       552.  POS  
##  2 carnivorous      461.  POS  
##  3 prey             210.  POS  
##  4 hunt             176.  POS  
##  5 numbers          170.  POS  
##  6 population       115.  POS  
##  7 ocean            110.  POS  
##  8 near              91.6 POS  
##  9 feet              87.8 POS  
## 10 hatch             86.1 POS  
## # â€¦ with 59 more rows
```

---

# Final fit

We will now use `last_fit()` to **fit** our model one last time on our training data and **evaluate** it on our testing data.


```r
final_fit &lt;- last_fit(
  wf_spec_final, 
  animals_split
)
```

```
## ! Resample1: model (predictions): There are new levels in a factor: NA
```

---

class: inverse, right, middle

# Notice that this is the **first** and **only** time we have used our **testing data**

---

# Evaluate on the **test** data ðŸ“


```r
final_fit %&gt;%
  collect_metrics()
```

```
## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.785
## 2 roc_auc  hand_till      0.910
```

---


```r
final_fit %&gt;%
  collect_predictions() %&gt;%
  conf_mat(truth = diet, .pred_class) %&gt;%
  autoplot(type = "heatmap")
```

&lt;img src="index_files/figure-html/unnamed-chunk-69-1.png" width="700px" style="display: block; margin: auto;" /&gt;

---

class: center, middle

# Thanks!

##[smltar.com](https://smltar.com/)

&lt;img style="border-radius: 50%;" src="https://github.com/EmilHvitfeldt.png" width="150px"/&gt;  
### <i class="fab  fa-github "></i> [EmilHvitfeldt](https://github.com/EmilHvitfeldt/)
### <i class="fab  fa-twitter "></i> [@Emil_Hvitfeldt](https://twitter.com/Emil_Hvitfeldt)
### <i class="fab  fa-linkedin "></i> [emilhvitfeldt](linkedin.com/in/emilhvitfeldt/)
### <i class="fas  fa-laptop "></i> [www.hvitfeldt.me](www.hvitfeldt.me)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
